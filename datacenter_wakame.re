= データセンターを Trema で作る

//lead{
執筆中です。
//}

== Trema と OSS でデータセンターを作ろう

一台のコンピュータ上で、リソースの管理や基本サービスの提供に OS が必要になるように、データセンターにも同じ機能を提供するソフトウェア階層が必要です。IaaS はその一つで、ユーザやアプリケーションに対して仮想的なリソースの貸し借りを行います。たとえば「192.168.0.1/24 のネットワークでつながった高性能サーバ 16 台がほしい」というリクエストを受けると、IaaS はスペックの高い VM を物理マシン上に起動し、専用の仮想ネットワークを作って VM 同士をつなぎます。このように、データセンターのリソースを仮想化して使いやすく提供するのが IaaS です。

IaaS のネットワーク仮想化には OpenFlow が適しています。(理由をここに)。IaaS では、必要なとき仮想ネットワークを作り、使い終われば削除します。また IaaS では多くのユーザを収容しているため、仮想ネットワーク作成・削除は、他のユーザに影響を与えないように行う必要があります。

== Wakame-VDC

Trema を利用した本格的な IaaS プラットフォームが、Wakame-VDC です。すでに九州電力など多くの企業のプライベートクラウド構築基盤として実績がある上、なんとすべてがオープンソースとして公開されています。

Wakame-VDC は、IaaS 型のクラウド構築基盤ソフトウェアです。オープンソースライセンスである LGPL v3 に基づき公開されています。開発は任意団体である Wakame Software Foundation (WSF) が行っています。2009 年 4 月に株式会社あくしゅによって、Ruby で書かれた最初のコードがコミットされて以来、2012 年 9 月現在で計 22 企業・団体が所属し、今もなお積極的に開発が継続されています。Wakame-VDC も開発者を募集しております。気軽にパッチを送ってください。Github なら、Pull Request と言うスタイルで、それを支援してくれます。

Wakame-VDC の情報は次の URL から入手できます。

 * Wakame-VDC開発リポジトリ: @<href>{https://github.com/axsh/wakame-vdc}
 * Wiki ドキュメント: @<href>{http://wakame.jp/wiki/}

== エッジスイッチによるネットワーク仮想化

Wakame-VDC は、@<chap>{sliceable_switch} とは異なり、OpenFlow 未対応のスイッチで構成されたネットワークで動作するよう設計されています。IaaS を構成する物理サーバ内で動作するソフトウェアスイッチのみを OpenFlow を用いて制御することで、仮想ネットワークを実現します。

仮想ネットワークで必要な機能は、ユーザ毎のトラフィックの分離です。Wakame-VDC ではエッジのスイッチの制御のみでこれを実現しています。基本的なアイディアは、エッジスイッチを、物理ネットワークと、仮想ネットワークの境界線と考えて、エッジスイッチで相互に乗り入れるための変換ルールを用意しておいて、うまく物理と仮想の間を行き来できるようにしようと言うものです。

仮想ネットワークで使えるパケットを、うまく物理ネットワークで使えるように書き換えて、目的のNICへパケットを届けます。受け取った側では、物理ネットワークを旅してきたパケットを、再び仮想ネットワーク向けに書き換えるのです。仮想マシンは、仮想ネットワークだけ知っていれば良く、エッジスイッチはその仮想ネットワーク用のパケットを、うまく物理ネットワークに流して届くように変換する方法を知っていれば良いと言うことになります。

== パケットの変換方法

仮想マシンが生成する仮想ネットワーク用のパケットを、物理ネットワーク向けに変換する方法は、色々あります。

最も有名な方法は、GREに代表される、トンネリング技術を使う方法です。実際は、仮想ネットワーク用のパケットそのものは書き換えず、物理ネットワークを通れる別のパケットを用意し、そのペイロードに包む方法です。このような手法をEncapsulationと言います。

Wakame-VDCでは、GREトンネルを使う方法も実験的に組み込まれていますが、より手軽で、高速な手法として、ARPパケットの制御を行う方法を紹介します。この仕組みは、ARPパケットのブロードキャストを制御し、目的となる仮想マシンのNICにだけ、的確にARPを届けることができれば、他の仮想マシンから見えなくなると言う原則に基づいています。

== ARPの制御のイメージ

Wakame-VDCは、エッジスイッチにOpen vSwitch (OVS)を利用しています。一つの例として、ARPがどのように届くのかを順を追って説明していきます。

（紙芝居）

このように、２台の仮想マシンの間にあるOVS間では、ARPのブロードキャストは物理ネットワークでは使われません。ARPは、OVSに指定されたルールによって物理ネットワークをユニキャストで通過するように変換されます。受け取った側のOVSは、元のARPに戻します。それから、ARPを目的の仮想マシンのNICだけに、あたかもブロードキャストされたかのように届けるのです。

これで、送った側の仮想マシンにも、受け取った側の仮想マシンにも、今までのARPと同じ挙動をしたように見せることができます。他の仮想マシンには一切分かりません。もし、他の仮想マシンが、ARPを偽装したとしても、SRCとDSTが一致しないものはDROPしてしまいます。

== Wakame-VDCの構成概要

ここまでは、仮想ネットワークについて注目した説明でした。Wakame-VDCは、全体の論理構成を図hogehogeのように、まとめています。

(全体の図)

Web UIから指示を受けて、Data Center Manager (dcmgr)と呼ばれるデータセンター全体のリソース管理をする中枢部分に司令が飛ぶと、実際に仮想マシンの準備や、仮想ネットワークの設定などが行われます。

必要な作業指示は、メッセージキュープロトコルであるAMQPのネットワークに流され、物理リソースの管理をしているエージェントに届き、処理されます。エージェントは、物理サーバに分散してインストールされており、各々が指示を受け取るようになっています。

特に、仮想マシンを収容するサーバで動作するエージェントは、Hyper Visor Agent (hva)と呼ばれており、これが仮想マシンを起動し、仮想ネットワークをセットアップします。

Wakame-VDCは、各物理サーバに常駐するhvaが、Tremaフレームワークを通じて、hvaと対になるようにローカルに配置されているOVSと連携します。つまり、Wakame-VDCは、分散するOpenFlowコントローラへ指示を出して、各コントローラが担当するOVSの設定をOpenFlowプロトコルで書き換えていると表現することができます。この辺りも、Tremaを活用した例としても特徴的な部分ではないでしょうか。

== なぜTremaを使い始めたのか

もともとWakame-VDCは、エッジスイッチとしてLinux BridgeのNetfilterを利用していました。物理サーバのホストOSに備わっているパケット制御の機構を用いて、ネットワークの操作をしていたのです。すでに、2010年11月には、いくつかの制約はあるものの、物理ネットワークの上に、仮想ネットワークを自由に組めるようになっていました。アーキテクチャも当時と変わっていません。

しかし、ホストOSに組み込まれた機能を使っているため、通信する度に、物理サーバのCPUを使ってしまいます。物理サーバには、仮想マシンも収容されていますので、仮想マシンのためにもCPUが使いたいのですが、今後はネットワークにもCPUを食われるようになりそうな懸念があったのです。未来のCPUの機能改善や、性能向上に期待しつつも、我々に出来ることは何かを模索していました。ネットワークの処理をオフロードする必要があると考えたのです。

その時に出会ったのが、OpenFlowでした。スイッチを制御する標準的なプロトコルとして、採用されれば、今ホストOS上で行なっている処理を、外部に出しても、OpenFlowを使って指示をすることはできます。オフロードを目論む私達にはぴったりの技術でした。あとは、OpenFlowコントローラとして、作りこみが必要だったので、フレームワークを探していたところ、Tremaが期待の星のように目の前に現れたのです。Wakame-VDCは、全てRubyで記述されていたのも幸いでした。早速Tremaのソースコードを読み、まずはフレームワークとしてのデザインが気に入りました。それからどう使っていくか、方針を決め、取り掛かったのが、2011年の秋頃でした。その後、Tremaの機能改善のため、パッチを送るなどして、何とかWakame-VDCへの組み込みが終わり、今は応用範囲を、より完全な仮想ネットワークへと進展させています。

== まとめ

Wakame-VDCがTremaフレームワークを使って得られた他の効果もあります。それは、ソースコードのパッチを送って以来、Trema開発者の方々と仲良くなれた事です。たまに一緒に飲みに行きますが、集まればOpenFlowの未来や、ギークな激論で盛り上がるかと思いきや、誰も一切そんな話なんてしません。ただの楽しい飲んだくれでございます。

飲み会はともかく、ソースコードのパッチを送る事はとても大切です。取り分け、オープンソースライセンスのコードは、自分で改善を施す事ができて初めて本来の意味を持ちます。ダウンロードして来て、使えるか、使えないかを判断するだけではいけません。もしあなたが、本当に技術者であり、開発者なのであれば、使えないと放棄する前に、使えるようにするためのコードを生み出さねばなりません。そうする事で世の中は一歩ずつ前に進んでいきます。さあ、パッチを書きましょう！あなたの力が世界を変えるのです。


== 以下ゴミ文章

//lead{
以下ゴミ文章です。
//}

== Wakame-VDCのプロジェクトの背景

IaaSが必要な背景として、近年、システム管理者によって取り扱われるサーバの数が、急激に増加していることが挙げられます。単純なWebシステムを構築しても、トラフィックが急増すれば、きちんと応答できるように、素早くサーバ数を増加させなければなりません。それだけインターネットを利用するユーザ数そのものも増えているのだと言えます。スマートフォンや、タブレットのようなモバイルデバイスを一人で何台も持ち歩く時代です。空いた時間があれば、人々はいつでもネットワークへアクセスをしています。こうした需要の増加が、Webシステムを含むサーバ側への負荷を増大させているのです。サーバを大量に用意し、管理できるようにしなければ、システム管理者の仕事量にも限界が訪れることでしょう。そして近い将来、ネットワークへアクセスするのは、人間だけではなくなります。モバイルデバイスに取り付けられたセンサーが、常時データをストリーミングするようになると考えられています。サーバ側には、人間のアクセス数以上に多くの通信がやって来るようになるでしょう。機械からの要求を捌くために必要となるサーバの数を、これまで通り人間の能力だけで管理できるとは思えません。

現時点でも、アクセスが増え続けており、人々はネットワーク上に大量のデータを残すようになりました。サイトへのアクセス履歴、人々が発するメッセージや、写真、動画など、ライフログと呼ばれるものがその代表例です。今やこのようなデータは、分析にかければ、人々が欲しているものを浮かび上がらせるに十分な量になってきました。しかし、分析には時間がかかります。今ただちに人々が欲しいものを知るには、分析を高速にしなければなりません。高速にしようと思えば思うほど、またもや大量のサーバが必要になるのです。サーバ１台ずつに分析の作業を分担させて解決することになります。

IaaSは大量のサーバを管理するためのソリューションとなります。システム管理者は、自分の作業の大部分をルーチンワーク化し、プログラムにして、いつでも繰り返し実行できるように準備をするようになります。そしてプログラムは、IaaSに備わっているWeb
APIを通じて、データセンターで用意できる全ての資源を自動的にコントロールします。今後、システム管理者が、直接的にシステムを管理することは少なくなるでしょう。システム管理者の仕事の大部分は、管理のためのプログラムを生成することと、それらを十分にテストすることへと変化します。

WSFでは、私達の生活を豊かにするのは、このようなコンピューティングパワーにあると信じています。その一方で、コンピュータの数が増加の一途を辿ったとしても、依然として簡単に扱えるようにする必要があるのです。Wakame-VDCが取るアプローチは、データセンター全体を仮想化することです。そして世の中のデータセンター全てを透過的に扱えるようにするべきだと考えています。Wakame-VDCのVDCは、Virtual
Data Centerの略で、そのような未来を表しています。

このコンセプトによって、WSFのビジョンである「世界中のデータセンタを、ひとつのコンピュータにする」ことを実現するのです。Wakame-VDCは、まさにこれを達成するために生まれたものです。

== 基本設計の方針

データセンター全体を仮想化する、とはどう言うことでしょうか。私達は、仮想化がもたらす大きなメリットの一つに、ポータビリティがある、と考えています。データセンターが仮想化されて、ポータビリティを持つと、移動や複製が簡単になることでしょう。異なる物理構造を持つデータセンター上であっても、仮想データセンターは動作するようになります。

例えば、データセンターで動作させられるシステム構成と同じものを、たった１台のコンピュータに格納して開発をすることができるようになります。物理的に全く構造が違うものであっても、仮想データセンターは動くのです。

そして、１台のコンピュータの上で完成したシステムは、1000台を越えるサーバが収容された巨大なデータセンターの上に複製することができ、やはり同じように動作するのです。これは、システム開発プロセスと、デプロイメントが大きく変化する瞬間です。このように、データセンターを仮想化することには大きなメリットがあると考えられるのです。

それでは、データセンター全体を仮想化するのに必要な物は何でしょうか。

一つは、仮想マシンです。これまで通り、データセンター内で取り扱われる複数のサーバを、それぞれ仮想マシンにすることができます。しかし、それで本当に十分でしょうか。データセンター内を改めて見なおしてみると、そこにはネットワークや、ストレージなど、いくつものアセットが存在しています。それが全て仮想化されるべき対象であることに気がつくのではないでしょうか。ここでは、特にネットワークの仮想化について述べます。

== 仮想ネットワークの実現方法

元々、Wakame-VDCは、2010年4月に初めてリリースされた時には、ネットワークの仮想化については特に機能が含まれておりませんでした。非常に多くの課題があると言うことだけが分かっていました。その後、全ての仮想マシン(インスタンス)のブリッジに、パケット制御をする仕掛けを入れれば、自由に論理ネットワークを作ることが出来ることが判明しました。それを2010年11月にSecurity
Groupsと呼んで、実装をし、リリースしたのです。これがWakame-VDCにおける仮想ネットワークの最初の実装です。

Security Groupsは、非常に単純な概念ですが、強力です。まず、通信ポリシーを記述したセットを定義します。これをセキュリティグループと呼び、論理名を付けて保存しておくことができます。インスタンスは、これらのセキュリティグループを、複数指定して起動することができます。セキュリティグループが指定されたインスタンスのブリッジには、該当するポリシーの通りに、パケットに対するルールが自動的に設定されます。

Security Groupsが面白いのは、記述できるポリシーの自由度が非常に高いところです。通信ポートの指定や、IPアドレスの指定をした通信の許可ルールを記述できる以外にも、他のユーザを含むセキュリティグループ名を指定することができるのです。IPアドレス指定との違いは、セキュリティグループ名の場合、動的に変化するIPアドレス群が指定されたことになります。これによって、セキュリティグループ間の通信制御ができます。例えば、"Load
Balancer"や、"Web Server"、"Application
Server"、"Database"など、役割の異なるセキュリティグループを定義し、それぞれの間の通信を許可できます。そのために、Web三層構造に代表される多層化された論理ネットワークを自在に定義することが可能なのです。

一言で表現すると、これは「全仮想マシンのブリッジに、分散したファイアウォールのルールを適宜イベンチュアルに適用していく仕組み」です。Wakame-VDCは、論理ネットワークが正しく保たれるように、設定を動的に変更していくのです。全て仮想マシンが動作するサーバ側でネットワークの処理をするため、エッジノードネットワーキングと呼ばれます。

この実装は、2010年11月時点では、LinuxカーネルモジュールであるNetfilterを用いていました。ブリッジNetfilterの内容をコントロールするために、iptablesやebtablesと言ったユーザ空間のコマンドを用いて実現されていました。この仕組みで、Wakame-VDCは、エッジノードへのパケットの出入りを全て管理できます。ソフトウェアの力によって、エッジノードのネットワーク処理が賢くなればなるほど、より自由なネットワークを定義できるようになるのです。いわゆる、Software
Defined Network
(SDN)です。そして、このネットワークは、物理ネットワークを選びません。物理スイッチに特殊な機能は必要なく、タグVLANさえも一切使用しないのです。

== 仮想ネットワークの実現方式の未来

エッジネットワーキングのアーキテクチャは強力で、ファイアウォールを始め、あらゆるネットワーク制御を組み込めることは前述した通りです。しかも、エッジネットワーキングは分散処理であるため、フィルタリングのコストを全てのエッジネットワーク側で、分割して負担します。これはスケーラビリティが非常に高いことを示していますが、エッジ側のコンピューティングリソースを少しだけ消費してしまっている、とも言えます。

現在、ネットワークの帯域は、1Gbから10Gbの時代へと移ろうとしており、今後もこの傾向は続くことでしょう。どんどん高速になるのです。当然ながら、送出できるパケットの量も比例して増えていきます。帯域を活かそうと思えば、CPUのクロックをそれだけ消費してしまいます。エッジノードのCPUは、ネットワークだけでなく、仮想マシンを動作させるのにも利用されています。CPUはすでに酷使されている状況であり、もう余裕がなくなりつつあります。

ここで考えられるシナリオは2つあります。CPUそのものが対応できるようになるシナリオと、役割の異なるハードウェアで作業分担(オフロード)をするシナリオです。WSFでは、前者に期待しつつも、後者のための配慮をすることとしました。Netfilterの欠点は、Linuxカーネルモジュールとして組み込まれるものであり、オフロードが難しい点にあります。Netfilter相当の処理が、カーネルから切り離されることを想定すると、処理に対してサービスを提供しなければなりません。

2011年に入り、折しもOpenFlowの話題が盛り上がって来ました。Flow
Tableの定義が、Netfilterと似ている点や、Flow
Tableの変更は、iptablesのようなカーネルと対話することが前提のコマンドではなく、リモートからアクセスできるプロトコルとして定義されていました。そして、本書のTremaのフレームワークを使うと、iptables相当のコントローラがRubyで簡単に記述できるのです。これで、将来的にはCPUのオフロードも狙えます。早速Netfilterを置き換える技術として、Open
vSwitchと、Tremaを組み合わせたものを試作しました。そうして、うまく置き換えができるのを確認し、この方針で行くことを決定したのです。

WSFは、OpenFlowの定義するプロトコルが、スイッチをサービス化する際の規格として優れている点と、CPUオフロードの可能性がある点に重要性を感じて、OpenFlowを採用しています。

そしてTremaを選択した理由は、3つあります。
(1) Wakame-VDC同様に、Rubyを用いてもフレームワークが使える点
(2) C言語で記述されたコア部分を含め、ソフトウェアデザインが綺麗で見通しが良く、優れた拡張性と、処理速度をバランス良く両立している点
(3) オープンソースライセンスである点

これらに強く惹かれました。特に、デザインが優れている事は重要です。OpenFlowそのものについて、良く知らなければならないのは代わりがありませんが、今後も発展し、変化し続けるこの技術を、Tremaのレイヤに託すことができます。私達が触れるのは、OpenFlowではなく、Tremaのフレームワークです。Wakame-VDCのプログラマには優れたデザインを持つフレームワークが必要です。将来性や、コミュニティや、実績数などで選択するものではありません。デザインが優れてさえいれば、オープンソースライセンスの基、自分たちでメンテナンスして行くことも出来るのですから。

== Tremaの活用

当時のTremaは、コントローラのメインループが独自の設計になっていて、その中にイベント処理が閉じ込められていました。そこにWakame-VDC用のイベント処理を追加したかったので、RubyのEvent
Machineに代表されるような、selectベースのメインループに変更する必要がありました。２ヶ月ほどかけてTremaのメインループを修正し、コミットしたところ、Tremaのコミュニティはこれをレビューし、快く取り込んでくれたのです。

この修正から、Wakame-VDCが持つイベントと、Tremaで作ったコントローラのイベント処理がシームレスに連動するようになりました。それから程なくして、Netfilterの実装は、Tremaで作った新しいコントローラに、すげ替えられたのです。2011年12月に、このバージョンはリリースされました。OpenFlow版のSecurity
Groupsが動作していました。

しかし残念ながら、執筆時点の最新版2012年8月版では、主にOpen
vSwitchの挙動に関する理由により、この機能は限定的なものへと変化しました。Open
vSwitchはKernelに組み込んで使うには、サポートされるべき実装がまだ必要であることと、また、Netfilterの方が、現時点のセキュリティグループの実装に向いていることが挙げられます。この状況も直ぐに改善されて、いずれは再びopenFlowで互換する実装が出来ることでしょう。

そのため、Open vSwitchの活用は、時間軸的にも、より未来を想定しています。現在の実装は、完全な仮想ネットワークを実現するために、Open
vSwitchを利用する方向へシフトしています。

== 完全な仮想ネットワークへ

2011年12月時点でまだ実現できていなかったのは、L3のマルチテナント化だけでした。IPアドレス空間を個々に持てなかったのです。これができれば、完全なネットワークの仮想化が実現できたと表現できるでしょう。

原理は簡単です。仮想マシンに付いているネットワークの出入り口に、必ずソフトウェアスイッチがあります。これがエッジネットワーキングです。ここで、仮想マシンに見せるパケットと、物理ネットワークを通るパケットを変換すれば良いのです。ソフトウェアスイッチが、仮想と物理の境界線になるのです。

この境界線に、仮想ネットワークと物理ネットワークをマッピングする仕掛けとして、Open
vSwitchとTremaが存在しています。Wakame-VDCは、Tremaを使い、ユーザの欲しいネットワークになるよう、スイッチをコントロールします。
現在は、仮想ネットワークを作るために、2つの方法を内蔵しています。ひとつはGRE
Tunnelをソフトウェアスイッチ間で張る方法と、ARPのブロードキャストを制御して通信可能な状態を作って行く方法です。前者は、L3を越えられるので、より広域なネットワークで利用されて行くために取り入れており、後者はL2のレベルで仮想化する方法です。ただし、GREは、パケットをカプセル化するため、そのオーバヘッドが生じます。仕組みは単純であるため、十分に高速ですが、ARPを制御するだけの後者の方法の方がより高速です。将来的には、この2つの方法に限らず、対応できるものを増やしていきます。

ここまで完成したものが、2012年3月に動作しています。

== Wakame-VDCの仮想ネットワーク概要

Tremaの利用例として最も面白いのは、仮想ネットワークの機能です。いくつか実装方法がありますが、ここではTremaを用いた、最もシンプルな仮想ネットワークの実現方法について説明をします。まず、最初に少しだけ、Wakame-VDCが、どのように機能するのか、全体像について述べておきます。

Wakame-VDCの全体構成は(図1)の通りで、非常にシンプルです。Web APIを備えたData Center Manager
(dcmgr)が中央に配置され、データセンター全体のリースやリソース管理を行なっています。メッセージングをするために、AMQPネットワークを介します。AMQPは、エンタープライズで利用されることを想定した、ワイヤレベルのメッセージングプロトコルです。オープンな仕様であるため、言語を越えて相互運用可能な実装を得ることができます。Wakame-VDCは、このメッセージングネットワークを巧みに利用し、管理すべきリソースと直接対話をしていきます。

現在、Wakame-VDCで管理できるデータセンターの原始的なリソースは、大きく３つあります。
(1) サーバ
(2) ネットワーク
(3) ストレージ

特に、仮想ネットワークでは、サーバとネットワークの管理が重要になります。Wakame-VDCは、この２つの管理をするために、リソースを直接操作するエージェントを用意しています。

サーバのリソースの操作は、仮想マシンを起動したり、終了させたりする操作になります。そのために、ホストOSにエージェントを導入し、ゲストOSとなる仮想マシンを操作します。このエージェントは、仮想マシンのハイパーバイザと対話をするため、Hyper
Visor Agent (hva)と呼ばれています。dcmgrから司令を受けて、仮想サーバの操作を行います。

ネットワークのリソースの操作も、実際はWakame-VDCのユニークで強力なアーキテクチャ固有のものです。通常、ネットワークの操作と言うと、物理スイッチや、物理ルータをコンソールポート経由で直接設定していく作業を想像するかも知れませんが、全く違うアプローチを取ります。Wakame-VDCは、仮想ネットワークのレイヤを物理ネットワーク機器の上に構築しません。Wakame-VDCでは、仮想サーバがそれぞれ物理ネットワークに接続されるところに、処理をフックして仮想化する仕掛けになっています。このフックをするために、ソフトウェアスイッチを配置します。

仮想マシンは、物理ネットワークのことを考慮することなく、自分の好きなネットワーク用のパケットを作って送出することができます。送出された全てのパケットは、物理ネットワークを通過する前に、ソフトウェアスイッチを通過します。仮想マシンが思い思いに送出したパケットは、ここで物理ネットワークを通過できるように、変換を行うのです。このようなパケット操作を、仮想マシンそれぞれに行います。

そのため、ネットワークのリソース操作は、このソフトウェアスイッチの操作をすることであるとも言えます。Wakame-VDCでは、hvaにその仕事を兼任させており、仮想マシンを操作するだけでなく、仮想ネットワークのために、ソフトウェアスイッチも操作するようになっています。(図2)に示されるように、仮想マシンを動作させる物理サーバ内には、ソフトウェアスイッチが仕込んであります。Wakame-VDCは、分散したスイッチを統合的に管理するアーキテクチャになっているのです。

(図2:IaaS / Trema + Open vSwitch)

Wakame-VDCは、この分散スイッチの設定を適宜変更し、全体として仮想的なネットワークになるように、一元的に管理します。

== 仮想ネットワークのモード

Wakame-VDCが目指す仮想ネットワークを実現する方法はいくつもあります。

最も有名な方法はGRE Tunnelを使う方法でしょう。概念は(図3)のように、スイッチ間でトンネルを作り、そのトンネルを仮想のLANケーブルのように見たてて、パケットを流し込むものです。L2レベルでつながったように見えますが、当然ながら、実際にLANケーブルが配線されるわけではありません。スイッチでは、送信したいパケットを、互いのスイッチに到達できる新しいパケットに梱包し直して送信します。受信した側のスイッチでは、そのパケットを荷解きし、そこから本来届くはずだったパケットを取り出して、目的のポートにフォワードするのです。このメカニズムは、先述した仮想マシンの出入り口に配置されたスイッチ間に、うまく当てはまります。

(図3:GRE)

GRE Tunnelは非常に有用な手法です。これ単体でも、議論すべきことが数多くありますが、今回はこれよりもシンプルなARPコントロールによる仮想ネットワークの例を見ていきましょう。

ARPコントロールの手法は、シンプルです。ただし、特別な工夫をしない限り、L2ネットワークとしてリーチできる範囲内でしか利用できません。使う技術や、ハードウェアスペックにも依りますが、仮想マシン数にすると、せいぜい1,000台程度管理できるレベルとお考えください。

一般にARPは、L2ネットワーク内で、IPアドレスからMACアドレスを知る為に使われます。まず、MACアドレスを知りたいコンピュータから、送信先であるIPアドレスを記載したARPパケットをブロードキャストします。該当するIPアドレスを持つコンピュータは、自分のMACアドレスを要求してきたコンピュータへ通知します。この仕組みによって、コンピュータを利用するユーザは、大抵IPアドレスだけを知っていれば、通信したいコンピュータを特定する事ができるのです。

では、コンピュータのグループを予め作成しておいて、ARPに対する応答を制御できたら、どのような事が起こるでしょうか。ARPのブロードキャストする対象を、自分が使っているコンピュータのグループだけに絞り込めれば、安全に自分だけのネットワークが作れるのです。ただ、ARPのブロードキャストは物理スイッチでは素直にブロードキャストされてしまいます。OpenFlowに対応した物理スイッチであれば制御できるかもしれません。しかし、IaaSには、もう少し手軽に試せる良いポイントがあります。それはエッジノードです。エッジノードに配置したソフトウェアスイッチによって、必要のないARPを排除(drop)します。こうすることで、物理スイッチに手を加える事なく、ソフトウェアだけで制御可能になります。ソフトウェアスイッチの下に、仮想マシンが配置されます。この様子を表すイメージは、(図4)のようになります。

(図4:エッジノードでARPの処理をする)

== ARPをコントロールするだけでできる仮想ネットワーク
一番簡単な2台の物理サーバ間での挙動を例に見て行きましょう。ここに、2つのネットワークを作ります。どちらもL3のレベルでは、同じIPアドレス体系を取るのですが、L2では分離されているため、L3のマルチテナント化が実現できていることを示すものです。

基本的には、Open vSwitchは、未知のARPに対してはdropを仕掛けます。

受け入れたいARPのパケットは、Open
vSwitchから、仮想マシンが持つNICそれぞれに、フォワードするように設定されます。最初に起動した仮想マシンAに対しては、特に何も定義されません。

次に新しい仮想マシンBが、ネットワークに追加された場合を示します。仮想マシンBの起動直後、Wakame-VDCの持つイベントネットワークから、該当するhvaを経由し、ネットワークの変更が通知されます。hvaは、Tremaフレームワークを通じて、Open
vSwitchに設定を適用します。

これで起動した2つの仮想マシンA, Bが疎通することを確認しましょう。特に問題はないみたいです。

次は、全く同じ設定で、異なるネットワークを作ります。使用するIPアドレスも同じです。ここに、最初の仮想マシンCを起動します。これは物理サーバとしては、仮想マシンAと同じ場所に起動されました。Wakame-VDCは、仮想マシンの配置場所を決定するために、スケジューラと言う概念を持っています。このアルゴリズムはプラガブルで、プリセットのアルゴリズムがいくつかある他、自分でもオリジナルのスケジューラが簡単に組み込めます。ここでは、空いているマシンに積極的に埋めて行くアルゴリズムが使われたため、出来るだけ均等に配置しようとします。

それでは、仮想マシンDを起動してみましょう。仮想マシンCと、仮想マシンDの間でARPを受け入れられるような設定になるはずですので、確認してみます。

いかがでしょうか。実際に仮想マシンC, Dの間でだけ通信ができています。

最終的な状況を図示すると、次のようになります。

ARPだけでも、簡単に仮想ネットワークが作れることが、ご理解いただけたのではないでしょうか。そして、これを実現するために、Wakame-VDCはTremaと連携して、OpenFlowの制御をして行きます。


=== Wakame-VDCのその他の情報

